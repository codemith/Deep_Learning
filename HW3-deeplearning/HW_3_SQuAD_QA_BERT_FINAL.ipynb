{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedfb67-96bc-4478-ba6b-9c650010ab79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForQuestionAnswering,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908b336-7502-451d-a748-9b08fd016bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360677aa-7fee-459b-817d-7616cc9a6dce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67544802-1b5e-4d03-88b5-d161e1f28a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Load training data\n",
    "with open('Spoken-SQuAD/spoken_train-v1.1.json', 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "# Load validation data\n",
    "with open('Spoken-SQuAD/spoken_test-v1.1.json', 'r') as f:\n",
    "    validation_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa09e96-7956-4a87-8d56-11b678ae15a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07aedb-57ff-469b-b1f9-8d4d19f3ab74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 37130\n",
      "Total validation examples: 5376\n"
     ]
    }
   ],
   "source": [
    "def prepare_examples_with_stride(data, tokenizer, max_length=512, stride=128):\n",
    "    examples = []\n",
    "    for article in data['data']:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                answers = qa.get('answers', [])\n",
    "                \n",
    "                # Skip examples without answers\n",
    "                if not answers:\n",
    "                    continue\n",
    "\n",
    "                answer = answers[0]\n",
    "                answer_text = answer['text']\n",
    "                start_char = answer['answer_start']\n",
    "                end_char = start_char + len(answer_text)\n",
    "            \n",
    "                tokenized_inputs = tokenizer(\n",
    "                    question,\n",
    "                    context,\n",
    "                    max_length=max_length,\n",
    "                    truncation='only_second',\n",
    "                    stride=stride,\n",
    "                    return_overflowing_tokens=True,\n",
    "                    return_offsets_mapping=True,\n",
    "                    padding='max_length'\n",
    "                )\n",
    "\n",
    "                # Map tokens\n",
    "                overflow_mapping = tokenized_inputs.pop('overflow_to_sample_mapping')\n",
    "                offset_mapping = tokenized_inputs.pop('offset_mapping')\n",
    "\n",
    "                for i in range(len(tokenized_inputs['input_ids'])):\n",
    "                    input_ids = tokenized_inputs['input_ids'][i]\n",
    "                    attention_mask = tokenized_inputs['attention_mask'][i]\n",
    "                    token_type_ids = tokenized_inputs['token_type_ids'][i]\n",
    "                    sequence_ids = tokenized_inputs.sequence_ids(i)\n",
    "\n",
    "                    context_start = sequence_ids.index(1)\n",
    "                    context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
    "\n",
    "                    offsets = offset_mapping[i]\n",
    "                    sample_index = overflow_mapping[i]\n",
    "\n",
    "                    \n",
    "                    if not (offsets[context_start][0] <= start_char and offsets[context_end][1] >= end_char):\n",
    "                       \n",
    "                        start_positions = 0\n",
    "                        end_positions = 0\n",
    "                    else:\n",
    "                        # Finding the start and end token indices\n",
    "                        token_start_index = context_start\n",
    "                        token_end_index = context_end\n",
    "\n",
    "                        while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                            token_start_index += 1\n",
    "                        start_positions = token_start_index - 1\n",
    "\n",
    "                        while token_end_index >= 0 and offsets[token_end_index][1] >= end_char:\n",
    "                            token_end_index -= 1\n",
    "                        end_positions = token_end_index + 1\n",
    "\n",
    "                    # example\n",
    "                    example = {\n",
    "                        'input_ids': input_ids,\n",
    "                        'attention_mask': attention_mask,\n",
    "                        'token_type_ids': token_type_ids,\n",
    "                        'start_positions': start_positions,\n",
    "                        'end_positions': end_positions,\n",
    "                        'question': question,\n",
    "                        'context': context,\n",
    "                        'answers': [answer_text]\n",
    "                    }\n",
    "                    examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Preprocess the data\n",
    "training_examples = prepare_examples_with_stride(training_data, tokenizer)\n",
    "validation_examples = prepare_examples_with_stride(validation_data, tokenizer)\n",
    "\n",
    "print(f\"Total training examples: {len(training_examples)}\")\n",
    "print(f\"Total validation examples: {len(validation_examples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d41118-d815-4b13-a230-ea4a93ba93c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(example['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(example['attention_mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(example['token_type_ids'], dtype=torch.long),\n",
    "            'start_positions': torch.tensor(example['start_positions'], dtype=torch.long),\n",
    "            'end_positions': torch.tensor(example['end_positions'], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32068b78-0cf5-4541-a9c5-8c34bb694bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2979884-e0fe-4a35-a38b-dc86b743eb21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating datasets\n",
    "train_dataset = QADataset(training_examples)\n",
    "val_dataset = QADataset(validation_examples)\n",
    "\n",
    "# Creating DataLoaders\n",
    "batch_size = 8 \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12c8cf-fadc-42b4-8f1b-c34a2e7eb4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12cc3e-ccac-47dc-8655-86060e1e5821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
    "epochs = 3 \n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178abab-6719-437c-bfec-a13173b3721e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, optimizer, scheduler, epochs, device, output_dir):\n",
    "    total_start_time = time.time()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n======== Epoch {epoch + 1}/{epochs} ========\")\n",
    "        print(\"Training...\")\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "        total_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", leave=False)):\n",
    "            optimizer.zero_grad()\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch['input_ids'],\n",
    "                    attention_mask=batch['attention_mask'],\n",
    "                    token_type_ids=batch['token_type_ids'],\n",
    "                    start_positions=batch['start_positions'],\n",
    "                    end_positions=batch['end_positions']\n",
    "                )\n",
    "                loss = outputs.loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            batch_loss = loss.item()\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            # Print batch loss every 500 steps\n",
    "            if (step + 1) % 500 == 0 or (step + 1) == len(train_dataloader):\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                elapsed = time.time() - epoch_start_time\n",
    "                print(f\"  Step {step + 1}/{len(train_dataloader)} - \"\n",
    "                      f\"Batch Loss: {batch_loss:.4f} - \"\n",
    "                      f\"Avg Loss: {total_loss / (step + 1):.4f} - \"\n",
    "                      f\"LR: {current_lr:.6f} - \"\n",
    "                      f\"Elapsed: {elapsed:.2f}s\")\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"\\nEpoch {epoch + 1} finished.\")\n",
    "        print(f\"  Average Training Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Epoch Training Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # Validation after each epoch\n",
    "        print(\"\\nRunning Validation...\")\n",
    "        val_start_time = time.time()\n",
    "        avg_val_loss = evaluate(model, val_dataloader, device)\n",
    "        val_time = time.time() - val_start_time\n",
    "        print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"  Validation Time: {val_time:.2f}s\")\n",
    "\n",
    "        # Computing evaluation metrics\n",
    "        print(\"\\nCalculating Metrics on Validation Set...\")\n",
    "        evaluate_metrics(model, validation_examples, device)\n",
    "\n",
    "        # Saving model after each epoch\n",
    "        epoch_output_dir = os.path.join(output_dir, f\"epoch_{epoch + 1}\")\n",
    "        if not os.path.exists(epoch_output_dir):\n",
    "            os.makedirs(epoch_output_dir)\n",
    "        model.save_pretrained(epoch_output_dir)\n",
    "        tokenizer.save_pretrained(epoch_output_dir)\n",
    "        print(f\"Model saved to {epoch_output_dir}\")\n",
    "\n",
    "    total_training_time = time.time() - total_start_time\n",
    "    print(f\"\\nTraining complete! Total training time: {total_training_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5c53c-9d02-465e-9b73-0d3929d02881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_eval_loss = 0.0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluating\", leave=False)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=batch['input_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                token_type_ids=batch['token_type_ids'],\n",
    "                start_positions=batch['start_positions'],\n",
    "                end_positions=batch['end_positions']\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % 100 == 0 or (step + 1) == len(dataloader):\n",
    "            print(f\"  Evaluation Step {step + 1}/{len(dataloader)} - \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_eval_loss = total_eval_loss / len(dataloader)\n",
    "    return avg_eval_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44863e25-945c-4524-a1a2-7ad57ac53d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lowercase, remove punctuation, articles, and extra whitespace.\"\"\"\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    def remove_punctuation(text):\n",
    "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    return white_space_fix(remove_articles(remove_punctuation(lower(s))))\n",
    "\n",
    "def compute_exact(a_gold, a_pred):\n",
    "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_tokens = normalize_answer(a_gold).split()\n",
    "    pred_tokens = normalize_answer(a_pred).split()\n",
    "    common = set(gold_tokens) & set(pred_tokens)\n",
    "    if not common:\n",
    "        return 0.0\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(gold_tokens)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521bd67-1578-4593-970b-72936d93f5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, examples, device):\n",
    "    model.eval()\n",
    "    exact_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for idx, example in enumerate(tqdm(examples, desc='Calculating Metrics')):\n",
    "        # Tokenize with offset mapping and overflow mapping\n",
    "        tokenized_inputs = tokenizer(\n",
    "            example['question'],\n",
    "            example['context'],\n",
    "            truncation='only_second',\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        offset_mapping = tokenized_inputs.pop('offset_mapping')\n",
    "        overflow_mapping = tokenized_inputs.pop('overflow_to_sample_mapping')\n",
    "\n",
    "        inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "           \n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Postprocessing to get the best answer from multiple chunks\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        all_answers = []\n",
    "        for i in range(start_logits.size(0)):\n",
    "            start_logit = start_logits[i]\n",
    "            end_logit = end_logits[i]\n",
    "            input_ids = inputs['input_ids'][i]\n",
    "            offsets = offset_mapping[i]\n",
    "\n",
    "            start_indexes = torch.argsort(start_logit, descending=True).tolist()[:20]\n",
    "            end_indexes = torch.argsort(end_logit, descending=True).tolist()[:20]\n",
    "\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Ensure that the end index is after the start index and the answer is not too long\n",
    "                    if start_index <= end_index and end_index - start_index + 1 <= 30:\n",
    "                        # Calculate the score for the answer span\n",
    "                        answer_score = start_logit[start_index] + end_logit[end_index]\n",
    "                        # Skip answers that are not in the context (sequence_ids=1)\n",
    "                        if inputs['token_type_ids'][i][start_index] != 1 or inputs['token_type_ids'][i][end_index] != 1:\n",
    "                            continue\n",
    "                        # Extracting answers using offsets\n",
    "                        start_char = offsets[start_index][0].item()\n",
    "                        end_char = offsets[end_index][1].item()\n",
    "                        predicted_answer = example['context'][start_char:end_char]\n",
    "                        all_answers.append((predicted_answer, answer_score))\n",
    "\n",
    "        if all_answers:\n",
    "            best_answer = max(all_answers, key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            best_answer = ''\n",
    "\n",
    "        # Ground truth answers\n",
    "        ground_truth_answers = example['answers']\n",
    "\n",
    "        \n",
    "        exact = max(compute_exact(gt, best_answer) for gt in ground_truth_answers)\n",
    "        f1 = max(compute_f1(gt, best_answer) for gt in ground_truth_answers)\n",
    "\n",
    "        exact_scores.append(exact)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        if (idx + 1) % 500 == 0 or (idx + 1) == len(examples):\n",
    "            avg_exact = sum(exact_scores) / len(exact_scores)\n",
    "            avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "            print(f\"  Processed {idx + 1}/{len(examples)} examples - \"\n",
    "                  f\"EM: {avg_exact:.4f} - F1: {avg_f1:.4f}\")\n",
    "\n",
    "    avg_exact = sum(exact_scores) / len(exact_scores)\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    print(f\"\\nFinal Exact Match (EM): {avg_exact:.4f}\")\n",
    "    print(f\"Final F1 Score: {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70686049-1be0-4240-9cc4-07c1de8dec2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_answers(model, questions, contexts, tokenizer, device):\n",
    "    model.eval()\n",
    "    answers = []\n",
    "\n",
    "    for question, context in zip(questions, contexts):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            truncation='only_second',\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        offset_mapping = tokenized_inputs.pop('offset_mapping')\n",
    "        overflow_mapping = tokenized_inputs.pop('overflow_to_sample_mapping')\n",
    "\n",
    "      \n",
    "        inputs = {k: v.to(device) for k, v in tokenized_inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        all_answers = []\n",
    "        for i in range(start_logits.size(0)):\n",
    "            start_logit = start_logits[i]\n",
    "            end_logit = end_logits[i]\n",
    "            input_ids = inputs['input_ids'][i]\n",
    "            offsets = offset_mapping[i]\n",
    "            token_type_ids = inputs['token_type_ids'][i]\n",
    "\n",
    "            start_indexes = torch.argsort(start_logit, descending=True).tolist()[:20]\n",
    "            end_indexes = torch.argsort(end_logit, descending=True).tolist()[:20]\n",
    "\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                   \n",
    "                    if start_index <= end_index and end_index - start_index + 1 <= 30:\n",
    "                        \n",
    "                        if token_type_ids[start_index] != 1 or token_type_ids[end_index] != 1:\n",
    "                            continue\n",
    "                        \n",
    "                        answer_score = start_logit[start_index] + end_logit[end_index]\n",
    "                        \n",
    "                        start_char = offsets[start_index][0].item()\n",
    "                        end_char = offsets[end_index][1].item()\n",
    "                        predicted_answer = context[start_char:end_char]\n",
    "                        all_answers.append((predicted_answer, answer_score))\n",
    "                        \n",
    "        if all_answers:\n",
    "            best_answer = max(all_answers, key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            best_answer = ''\n",
    "\n",
    "        answers.append(best_answer)\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da7a0f5-058c-497c-8319-adbf217136d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = './models/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4154f0f3-b867-4777-9527-73bff0c42ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.995155/ipykernel_1527704/1203427822.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1/3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/4642 [00:00<?, ?it/s]/local_scratch/slurm.995155/ipykernel_1527704/1203427822.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1:  11%|█         | 503/4642 [00:24<03:05, 22.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 500/4642 - Batch Loss: 2.2808 - Avg Loss: 4.3370 - LR: 0.000011 - Elapsed: 24.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  22%|██▏       | 1004/4642 [00:47<02:43, 22.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1000/4642 - Batch Loss: 1.6811 - Avg Loss: 3.3355 - LR: 0.000022 - Elapsed: 46.85s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 1502/4642 [01:09<02:24, 21.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1500/4642 - Batch Loss: 1.9018 - Avg Loss: 2.8516 - LR: 0.000030 - Elapsed: 69.65s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  43%|████▎     | 2003/4642 [01:32<01:58, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 2000/4642 - Batch Loss: 1.2167 - Avg Loss: 2.5638 - LR: 0.000029 - Elapsed: 92.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  54%|█████▍    | 2504/4642 [01:55<01:38, 21.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 2500/4642 - Batch Loss: 1.4181 - Avg Loss: 2.3677 - LR: 0.000027 - Elapsed: 115.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  65%|██████▍   | 3002/4642 [02:18<01:13, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3000/4642 - Batch Loss: 1.3757 - Avg Loss: 2.2256 - LR: 0.000026 - Elapsed: 138.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▌  | 3503/4642 [02:41<00:51, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3500/4642 - Batch Loss: 1.0670 - Avg Loss: 2.1165 - LR: 0.000025 - Elapsed: 160.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  86%|████████▋ | 4004/4642 [03:03<00:29, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4000/4642 - Batch Loss: 1.0638 - Avg Loss: 2.0319 - LR: 0.000024 - Elapsed: 183.82s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  97%|█████████▋| 4502/4642 [03:26<00:06, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4500/4642 - Batch Loss: 0.9653 - Avg Loss: 1.9592 - LR: 0.000023 - Elapsed: 206.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4642/4642 - Batch Loss: 1.6729 - Avg Loss: 1.9411 - LR: 0.000022 - Elapsed: 212.85s\n",
      "\n",
      "Epoch 1 finished.\n",
      "  Average Training Loss: 1.9411\n",
      "  Epoch Training Time: 212.85s\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  15%|█▌        | 102/672 [00:05<00:31, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 100/672 - Loss: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 202/672 [00:11<00:26, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 200/672 - Loss: 0.5966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  45%|████▍     | 302/672 [00:16<00:20, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 300/672 - Loss: 1.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|█████▉    | 402/672 [00:22<00:15, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 400/672 - Loss: 2.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  75%|███████▍  | 502/672 [00:28<00:09, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 500/672 - Loss: 1.3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|████████▉ | 602/672 [00:33<00:03, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 600/672 - Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 672/672 - Loss: 1.6201\n",
      "  Validation Loss: 1.5099\n",
      "  Validation Time: 37.50s\n",
      "\n",
      "Calculating Metrics on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:   9%|▉         | 505/5376 [00:13<02:00, 40.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/5376 examples - EM: 0.5680 - F1: 0.6654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  19%|█▊        | 1006/5376 [00:26<01:59, 36.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1000/5376 examples - EM: 0.5670 - F1: 0.6775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  28%|██▊       | 1504/5376 [00:40<01:48, 35.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1500/5376 examples - EM: 0.5427 - F1: 0.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  37%|███▋      | 2005/5376 [00:53<01:21, 41.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2000/5376 examples - EM: 0.5375 - F1: 0.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  47%|████▋     | 2505/5376 [01:05<00:58, 49.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2500/5376 examples - EM: 0.5296 - F1: 0.6775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  56%|█████▌    | 3008/5376 [01:16<00:48, 48.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3000/5376 examples - EM: 0.5333 - F1: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  65%|██████▌   | 3507/5376 [01:26<00:37, 49.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3500/5376 examples - EM: 0.5280 - F1: 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  75%|███████▍  | 4006/5376 [01:36<00:26, 51.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 4000/5376 examples - EM: 0.5305 - F1: 0.6759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  84%|████████▍ | 4508/5376 [01:48<00:22, 39.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 4500/5376 examples - EM: 0.5298 - F1: 0.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  93%|█████████▎| 5003/5376 [02:01<00:09, 39.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 5000/5376 examples - EM: 0.5334 - F1: 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 5376/5376 [02:10<00:00, 41.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 5376/5376 examples - EM: 0.5320 - F1: 0.6763\n",
      "\n",
      "Final Exact Match (EM): 0.5320\n",
      "Final F1 Score: 0.6763\n",
      "Model saved to ./models/epoch_1\n",
      "\n",
      "======== Epoch 2/3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  11%|█         | 504/4642 [00:23<03:11, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 500/4642 - Batch Loss: 0.5957 - Avg Loss: 0.8846 - LR: 0.000021 - Elapsed: 23.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  22%|██▏       | 1002/4642 [00:46<02:47, 21.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1000/4642 - Batch Loss: 1.3091 - Avg Loss: 0.9102 - LR: 0.000020 - Elapsed: 46.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  32%|███▏      | 1503/4642 [01:08<02:21, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1500/4642 - Batch Loss: 1.3460 - Avg Loss: 0.9202 - LR: 0.000019 - Elapsed: 68.55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  43%|████▎     | 2004/4642 [01:31<01:58, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 2000/4642 - Batch Loss: 0.3092 - Avg Loss: 0.9276 - LR: 0.000017 - Elapsed: 91.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  54%|█████▍    | 2502/4642 [01:53<01:36, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 2500/4642 - Batch Loss: 1.3931 - Avg Loss: 0.9288 - LR: 0.000016 - Elapsed: 113.79s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  65%|██████▍   | 3003/4642 [02:16<01:15, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3000/4642 - Batch Loss: 2.1768 - Avg Loss: 0.9294 - LR: 0.000015 - Elapsed: 136.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  75%|███████▌  | 3504/4642 [02:39<00:52, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3500/4642 - Batch Loss: 0.9917 - Avg Loss: 0.9327 - LR: 0.000014 - Elapsed: 159.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  86%|████████▌ | 4002/4642 [03:02<00:29, 21.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4000/4642 - Batch Loss: 1.0818 - Avg Loss: 0.9265 - LR: 0.000013 - Elapsed: 182.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  97%|█████████▋| 4503/4642 [03:25<00:06, 22.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4500/4642 - Batch Loss: 0.4745 - Avg Loss: 0.9215 - LR: 0.000011 - Elapsed: 205.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4642/4642 - Batch Loss: 0.3068 - Avg Loss: 0.9211 - LR: 0.000011 - Elapsed: 211.64s\n",
      "\n",
      "Epoch 2 finished.\n",
      "  Average Training Loss: 0.9211\n",
      "  Epoch Training Time: 211.64s\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  15%|█▌        | 102/672 [00:05<00:31, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 100/672 - Loss: 0.6542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 202/672 [00:11<00:26, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 200/672 - Loss: 0.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  45%|████▍     | 302/672 [00:16<00:20, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 300/672 - Loss: 1.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|█████▉    | 402/672 [00:22<00:15, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 400/672 - Loss: 1.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  75%|███████▍  | 502/672 [00:27<00:09, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 500/672 - Loss: 0.9548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|████████▉ | 602/672 [00:33<00:03, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 600/672 - Loss: 1.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 672/672 - Loss: 1.6122\n",
      "  Validation Loss: 1.4853\n",
      "  Validation Time: 37.47s\n",
      "\n",
      "Calculating Metrics on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:   9%|▉         | 507/5376 [00:10<01:44, 46.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/5376 examples - EM: 0.5980 - F1: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  19%|█▉        | 1008/5376 [00:22<01:37, 44.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1000/5376 examples - EM: 0.5910 - F1: 0.6999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  28%|██▊       | 1508/5376 [00:33<01:28, 43.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1500/5376 examples - EM: 0.5613 - F1: 0.6922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  37%|███▋      | 2007/5376 [00:44<01:08, 48.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2000/5376 examples - EM: 0.5570 - F1: 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  47%|████▋     | 2507/5376 [00:55<00:58, 49.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2500/5376 examples - EM: 0.5532 - F1: 0.6937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  56%|█████▌    | 3005/5376 [01:05<00:48, 48.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3000/5376 examples - EM: 0.5537 - F1: 0.6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  65%|██████▌   | 3509/5376 [01:16<00:37, 49.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3500/5376 examples - EM: 0.5474 - F1: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  74%|███████▍  | 4005/5376 [01:26<00:27, 49.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 4000/5376 examples - EM: 0.5465 - F1: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  84%|████████▍ | 4506/5376 [01:36<00:17, 49.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 4500/5376 examples - EM: 0.5458 - F1: 0.6861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  93%|█████████▎| 5010/5376 [01:47<00:07, 48.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 5000/5376 examples - EM: 0.5482 - F1: 0.6889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 5376/5376 [01:55<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 5376/5376 examples - EM: 0.5452 - F1: 0.6867\n",
      "\n",
      "Final Exact Match (EM): 0.5452\n",
      "Final F1 Score: 0.6867\n",
      "Model saved to ./models/epoch_2\n",
      "\n",
      "======== Epoch 3/3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  11%|█         | 504/4642 [00:22<03:04, 22.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 500/4642 - Batch Loss: 0.1564 - Avg Loss: 0.5050 - LR: 0.000010 - Elapsed: 22.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  22%|██▏       | 1002/4642 [00:44<02:42, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1000/4642 - Batch Loss: 0.1294 - Avg Loss: 0.4985 - LR: 0.000009 - Elapsed: 44.70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  32%|███▏      | 1503/4642 [01:07<02:20, 22.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 1500/4642 - Batch Loss: 1.8543 - Avg Loss: 0.4968 - LR: 0.000008 - Elapsed: 67.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  43%|████▎     | 2004/4642 [01:29<01:57, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 2000/4642 - Batch Loss: 0.4932 - Avg Loss: 0.4983 - LR: 0.000006 - Elapsed: 89.71s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  54%|█████▍    | 2502/4642 [01:52<01:35, 22.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 2500/4642 - Batch Loss: 0.3011 - Avg Loss: 0.4967 - LR: 0.000005 - Elapsed: 112.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  65%|██████▍   | 3003/4642 [02:14<01:15, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3000/4642 - Batch Loss: 0.4315 - Avg Loss: 0.4966 - LR: 0.000004 - Elapsed: 134.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  75%|███████▌  | 3504/4642 [02:37<00:51, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 3500/4642 - Batch Loss: 0.3354 - Avg Loss: 0.4949 - LR: 0.000003 - Elapsed: 157.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  86%|████████▌ | 4002/4642 [03:00<00:28, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4000/4642 - Batch Loss: 0.1581 - Avg Loss: 0.4898 - LR: 0.000002 - Elapsed: 180.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  97%|█████████▋| 4503/4642 [03:22<00:06, 22.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4500/4642 - Batch Loss: 0.3077 - Avg Loss: 0.4900 - LR: 0.000000 - Elapsed: 202.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Step 4642/4642 - Batch Loss: 0.7115 - Avg Loss: 0.4880 - LR: 0.000000 - Elapsed: 209.00s\n",
      "\n",
      "Epoch 3 finished.\n",
      "  Average Training Loss: 0.4880\n",
      "  Epoch Training Time: 209.00s\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  15%|█▌        | 102/672 [00:05<00:31, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 100/672 - Loss: 0.9461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|███       | 202/672 [00:11<00:26, 17.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 200/672 - Loss: 0.4653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  45%|████▍     | 302/672 [00:16<00:20, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 300/672 - Loss: 1.5343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  60%|█████▉    | 402/672 [00:22<00:15, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 400/672 - Loss: 1.5408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  75%|███████▍  | 502/672 [00:27<00:09, 17.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 500/672 - Loss: 1.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  90%|████████▉ | 602/672 [00:33<00:03, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 600/672 - Loss: 1.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation Step 672/672 - Loss: 1.5950\n",
      "  Validation Loss: 1.7295\n",
      "  Validation Time: 37.49s\n",
      "\n",
      "Calculating Metrics on Validation Set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:   9%|▉         | 509/5376 [00:10<01:40, 48.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/5376 examples - EM: 0.5840 - F1: 0.6828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  19%|█▉        | 1009/5376 [00:21<01:37, 44.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1000/5376 examples - EM: 0.5910 - F1: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  28%|██▊       | 1505/5376 [00:33<01:28, 43.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 1500/5376 examples - EM: 0.5607 - F1: 0.6933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  37%|███▋      | 2009/5376 [00:44<01:09, 48.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2000/5376 examples - EM: 0.5570 - F1: 0.6979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  47%|████▋     | 2509/5376 [00:55<00:58, 48.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 2500/5376 examples - EM: 0.5544 - F1: 0.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  56%|█████▌    | 3005/5376 [01:05<00:47, 49.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3000/5376 examples - EM: 0.5547 - F1: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  65%|██████▌   | 3505/5376 [01:16<00:36, 51.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 3500/5376 examples - EM: 0.5506 - F1: 0.6952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  74%|███████▍  | 4004/5376 [01:26<00:27, 49.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 4000/5376 examples - EM: 0.5505 - F1: 0.6974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  84%|████████▍ | 4509/5376 [01:37<00:18, 48.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 4500/5376 examples - EM: 0.5502 - F1: 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics:  93%|█████████▎| 5010/5376 [01:48<00:07, 47.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 5000/5376 examples - EM: 0.5526 - F1: 0.6977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Metrics: 100%|██████████| 5376/5376 [01:56<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 5376/5376 examples - EM: 0.5506 - F1: 0.6962\n",
      "\n",
      "Final Exact Match (EM): 0.5506\n",
      "Final F1 Score: 0.6962\n",
      "Model saved to ./models/epoch_3\n",
      "\n",
      "Training complete! Total training time: 1110.87s\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    "    output_dir=output_dir\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421ac93-274a-4b52-bdc5-c3620af64761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n",
      "Answer: Paris\n"
     ]
    }
   ],
   "source": [
    "# Trial \n",
    "questions = [\"What is the capital of France?\"]\n",
    "contexts = [\"France, officially the French Republic, is a country whose territory consists of metropolitan France in Western Europe and several overseas regions and territories. The capital is Paris.\"]\n",
    "predicted_answers = predict_answers(model, questions, contexts, tokenizer, device)\n",
    "\n",
    "for question, answer in zip(questions, predicted_answers):\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
